{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXtTcMemGoRa"
   },
   "source": [
    "### 1. Setup enviroment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.naturalistic-neuroimaging-database.org/annotations#Header8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fl3giKwRGWl7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "from moviepy.editor import *\n",
    "from IPython.display import Video, clear_output, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# little_miss_sunshine annotation has delay of +2.6\n",
    "# little_miss_sunshine annotation has delay of -8.8\n",
    "# usar o dataset de palasvras p acertar a sincronizacao do tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e39djzWSGn6v",
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie = VideoFileClip(\"the_prestige.mkv\")\n",
    "faces_times = pd.read_csv('the_prestige_faces.txt', sep=':', header=0, names=['onset', 'duration'])\n",
    "words_times = pd.read_csv('the_prestige_words.csv', sep=',', header=0, names=['subtitle', 'start_time_new', 'end_time_new', 'interval_new', 'type'])\n",
    "\n",
    "faces_times['onset_old'] = faces_times['onset'] \n",
    "faces_times['onset'] = faces_times['onset_old'] -8.8\n",
    "faces_times = faces_times[faces_times['onset']>0].reset_index(drop=True)\n",
    "faces_times = faces_times[['onset','duration']]\n",
    "faces_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get clips (images and audio) with faces  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgfEAkFCIP6C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_audio_and_image(movie, start_time, end_time):\n",
    "    video = movie.subclip(start_time, end_time)\n",
    "    images = movie.subclip(start_time, end_time).without_audio()\n",
    "    audio = movie.audio.subclip(start_time, end_time)\n",
    "    return video, images, audio\n",
    "    \n",
    "\n",
    "def get_clips(movie, times, label):\n",
    "    clips = {}\n",
    "    for index, times in tqdm(times.iterrows(), total=times.shape[0], desc=\"Extracting clips\"):\n",
    "        onset_time = times['onset']\n",
    "        duration = times['duration']\n",
    "        end_time = onset_time + duration\n",
    "        video, images, audio = extract_audio_and_image(movie, float(onset_time), float(end_time))\n",
    "        clips_data = {\n",
    "            'onset': onset_time,\n",
    "            'duration': duration,\n",
    "            'label': label,\n",
    "            'video': video,\n",
    "            'audio': audio,\n",
    "            'images': images\n",
    "        }\n",
    "        clips[index] = clips_data\n",
    "    return clips\n",
    "\n",
    "\n",
    "def get_inverted_times(movie, times, epsilon = 0.1, threshold = 1):\n",
    "    # getting inverted times\n",
    "    df = faces_times.copy()\n",
    "    df['onset_end'] = df['onset'] + df['duration'] \n",
    "    df['offset_start'] = df['onset'] + df['duration'] + epsilon\n",
    "    df['offset_end'] = pd.concat([df['onset'].iloc[1:], pd.Series(movie.duration)], ignore_index=True) - epsilon \n",
    "    df['offset_duration'] = df['offset_end'] - df['offset_start'] \n",
    "    first_row = pd.DataFrame({'onset': [np.nan], 'duration': [np.nan], 'onset_end': [np.nan],\n",
    "                              'offset_start': [0], 'offset_duration':df.iloc[0,0]- epsilon , 'offset_end':df.iloc[0,0]- epsilon})\n",
    "    df = pd.concat([first_row, df], ignore_index=True).round(1)\n",
    "    # new\n",
    "    inverted_times = df[['offset_start','offset_duration']]\n",
    "    inverted_times.rename(columns={'offset_start':'onset','offset_duration':'duration'}, inplace = True)\n",
    "    # drop durations too small\n",
    "    inverted_times = inverted_times[(inverted_times.duration > threshold)].reset_index(drop=True)\n",
    "    return inverted_times\n",
    "\n",
    "\n",
    "def preview_movie(clip):\n",
    "    temp_file = tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False)\n",
    "    clip.write_videofile(temp_file.name, codec=\"libx264\")\n",
    "    clip_final = Video(temp_file.name, embed=True)\n",
    "    return clip_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_with_faces = get_clips(movie, times=faces_times[:300], label='has_faces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_with_faces[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "print(clips_with_faces[index])\n",
    "preview_movie(clips_with_faces[index]['video'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = [clip['video'] for clip in clips_with_faces.values()]\n",
    "concat_clips = concatenate_videoclips(clips)\n",
    "preview_movie(concat_clips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_without_faces = get_inverted_times(movie, faces_times, epsilon = 0.1, threshold = 1)\n",
    "times_without_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_without_faces = get_clips(movie, times=times_without_faces[:-1], label='no_faces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "print(clips_without_faces[index])\n",
    "preview_movie(clips_without_faces[index]['video'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = [clip['video'] for clip in clips_without_faces.values()]\n",
    "concat_clips = concatenate_videoclips(clips)\n",
    "preview_movie(concat_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
